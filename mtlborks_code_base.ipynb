{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea841233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import random \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scipy.spatial.distance import euclidean\n",
    "import logging\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a2ddbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 19\n",
    "N = 20\n",
    "\n",
    "T_max =  10\n",
    "\n",
    "NConv_min =  1\n",
    "NConv_max =  3\n",
    "\n",
    "NFil_min =  3\n",
    "NFil_max =  256\n",
    "\n",
    "SKer_min =  3\n",
    "SKer_max =  9\n",
    "\n",
    "SPool_min =  1\n",
    "SPool_max =  3\n",
    "\n",
    "SStr_min =  1\n",
    "SStr_max =  2\n",
    "\n",
    "NFc_min =  1\n",
    "NFc_max =  2\n",
    "\n",
    "NNeu_min =  1\n",
    "NNeu_max =  300\n",
    "\n",
    "S_batch =  128\n",
    "\n",
    "epochs_fitness =  1\n",
    "epochs_full_training  = 100\n",
    "R_L  = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b0a4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_constraints(offspring_vec,\n",
    "                      NConv_min, NConv_max,\n",
    "                      NFil_min, NFil_max,\n",
    "                      SKer_min, SKer_max,\n",
    "                      SPool_min, SPool_max,\n",
    "                      SStr_min, SStr_max,\n",
    "                      NFc_min, NFc_max,\n",
    "                      NNeu_min, Nneu_max):\n",
    "    logging.info(\"doing boundry check  and rounding integer of new offspring generated in teacher phase\")\n",
    "    D = len(offspring_vec)\n",
    "    \n",
    "    #N_conv\n",
    "    offspring_vec[0] = np.clip(offspring_vec[0], NConv_min, NConv_max)\n",
    "    # Conv layers\n",
    "    for l in range(1, NConv_max + 1):\n",
    "        offspring_vec[2*l - 1] = np.clip(offspring_vec[2*l - 1], NFil_min, NFil_max)\n",
    "        offspring_vec[2*l] = np.clip(offspring_vec[2*l], SKer_min, SKer_max)\n",
    "    #Pool layers\n",
    "    base_idx = 2 * NConv_max\n",
    "    for l in range(1, NConv_max + 1):\n",
    "        offspring_vec[base_idx + 3*l - 2] = np.clip(offspring_vec[base_idx + 3*l - 2], 0, 1) # P_pool\n",
    "        offspring_vec[base_idx + 3*l - 1] = np.clip(offspring_vec[base_idx + 3*l - 1], SPool_min, SPool_max)\n",
    "        offspring_vec[base_idx + 3*l] = np.clip(offspring_vec[base_idx + 3*l], SStr_min, SStr_max)\n",
    "    # N_fc\n",
    "    fc_base_idx = 5 * NConv_max + 1\n",
    "    offspring_vec[fc_base_idx] = np.clip(offspring_vec[fc_base_idx], NFc_min, NFc_max)\n",
    "    # FC layers\n",
    "    for q in range(1, NFc_max + 1):\n",
    "        offspring_vec[fc_base_idx + q] = np.clip(offspring_vec[fc_base_idx + q],NNeu_min, Nneu_max)\n",
    "        \n",
    "    #rounding\n",
    "    offspring_vec[0] = round(offspring_vec[0])\n",
    "    for l in range(1, NConv_max + 1):\n",
    "        offspring_vec[2*l - 1] = round(offspring_vec[2*l - 1])\n",
    "        offspring_vec[2*l] = round(offspring_vec[2*l])\n",
    "    base_idx = 2 * NConv_max\n",
    "    for l in range(1, NConv_max + 1):\n",
    "        #do NOT round the P_pool probability\n",
    "        offspring_vec[base_idx + 3*l - 1] = round(offspring_vec[base_idx + 3*l - 1])\n",
    "        offspring_vec[base_idx + 3*l] = round(offspring_vec[base_idx + 3*l])\n",
    "    fc_base_idx = 5 * NConv_max + 1\n",
    "    offspring_vec[fc_base_idx] = round(offspring_vec[fc_base_idx])\n",
    "    for q in range(1, NFc_max + 1):\n",
    "        offspring_vec[fc_base_idx + q] = round(offspring_vec[fc_base_idx + q])\n",
    "        \n",
    "    return offspring_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5eed39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_arrays(NConv_min, NConv_max,\n",
    "    NFil_min, NFil_max,\n",
    "    SKer_min, SKer_max,\n",
    "    SPool_min, SPool_max,\n",
    "    SStr_min, SStr_max,\n",
    "    NFC_min, NFC_max,\n",
    "    NNeu_min, NNeu_max):\n",
    "    logging.info(\"xmin and xmax initialize\")\n",
    "    D = 5 * NConv_max + NFC_max + 2\n",
    "    X_min = np.zeros(D)\n",
    "    X_max = np.zeros(D)\n",
    "    # N_conv\n",
    "    X_min[0], X_max[0] = NConv_min, NConv_max\n",
    "    # Conv layers\n",
    "    for l in range(1, NConv_max + 1):\n",
    "        X_min[2*l - 1], X_max[2*l - 1] = NFil_min, NFil_max\n",
    "        X_min[2*l], X_max[2*l] = SKer_min, SKer_max\n",
    "    # Pool layers\n",
    "    base_idx = 2 * NConv_max\n",
    "    for l in range(1, NConv_max + 1):\n",
    "        X_min[base_idx + 3*l - 2], X_max[base_idx + 3*l - 2] = 0.0, 1.0\n",
    "        X_min[base_idx + 3*l - 1], X_max[base_idx + 3*l - 1] = SPool_min, SPool_max\n",
    "        X_min[base_idx + 3*l], X_max[base_idx + 3*l] = SStr_min, SStr_max\n",
    "    # N_fc\n",
    "    fc_base_idx = 5 * NConv_max + 1\n",
    "    X_min[fc_base_idx], X_max[fc_base_idx] = NFC_min, NFC_max\n",
    "    # FC layers\n",
    "    for q in range(1, NFC_max + 1):\n",
    "        X_min[fc_base_idx + q], X_max[fc_base_idx + q] = NNeu_min, NNeu_max\n",
    "    logging.info(f\"xmax {X_max}\\nx min  {X_min}\")\n",
    "    return X_min, X_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cbbe52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_learning_schema(learner,teacher,\n",
    "                        X_max, X_min,\n",
    "                        NConv_min, NConv_max,\n",
    "                        NFil_min, NFil_max,\n",
    "                        SKer_min, SKer_max,\n",
    "                        SPool_min, SPool_max,\n",
    "                        SStr_min, SStr_max,\n",
    "                        NFc_min, NFc_max,\n",
    "                        NNeu_min, Nneu_max,\n",
    "                        R_train, R_valid,S_batch = 128, ε_train = 1,\n",
    "                        R_L = 0.001, C_num = 10,\n",
    "                        input_shape =  (28,28,1)\n",
    "                        ):\n",
    "    D = len(learner[\"vector\"])\n",
    "    Xn = learner[\"vector\"].copy()\n",
    "    d_rand = random.randint(0, D - 1)\n",
    "    r5 = random.uniform(-1, 1)\n",
    "    Xn[d_rand] += r5 * (X_max[d_rand] - X_min[d_rand])\n",
    "    Xn = apply_constraints(Xn,\n",
    "                NConv_min, NConv_max,\n",
    "                NFil_min, NFil_max,\n",
    "                SKer_min, SKer_max,\n",
    "                SPool_min, SPool_max,\n",
    "                SStr_min, SStr_max,\n",
    "                NFc_min, NFc_max,\n",
    "                NNeu_min, Nneu_max )\n",
    "    \n",
    "    fitness_self_learner = evaluate_fitness(Xn, R_train, R_valid, NConv_max,S_batch = 128, ε_train = 1,\n",
    "                                    R_L = 0.001, C_num = 10,\n",
    "                                    input_shape =  (28,28,1))\n",
    "    if fitness_self_learner < learner['fitness']:\n",
    "        updated_learner = {\"vector\": Xn, \"fitness\": fitness_self_learner}\n",
    "        if fitness_self_learner < teacher['fitness']:\n",
    "            teacher['vector'] = Xn.copy()\n",
    "            teacher['fitness'] = fitness_self_learner\n",
    "            logging.info(f\"New Teacher found via Self-Learning Fitness: {fitness_self_learner:.4f} ***\")\n",
    "        return updated_learner,teacher\n",
    "    else:\n",
    "        return learner, teacher\n",
    "\n",
    "\n",
    "def adaptive_peer_learning(n, P_off, teacher,NConv_min, NConv_max,\n",
    "                                NFil_min, NFil_max,\n",
    "                                SKer_min, SKer_max,\n",
    "                                SPool_min, SPool_max,\n",
    "                                SStr_min, SStr_max,\n",
    "                                NFc_min, NFc_max,\n",
    "                                NNeu_min, Nneu_max,R_train,R_valid,S_batch = 128, ε_train = 1,\n",
    "                                R_L = 0.001, C_num = 10,\n",
    "                                input_shape =  (28,28,1)):\n",
    "    N = len(P_off)\n",
    "    D = len(P_off[0]['vector'])\n",
    "    learner = P_off[n]\n",
    "    Xn = learner['vector'].copy()\n",
    "    rank = (N - 1) - n\n",
    "    p_n_PL = rank / N\n",
    "    peer_indices = list(range(N))\n",
    "    peer_indices.remove(n)\n",
    "    p, s, u = random.sample(peer_indices, 3)\n",
    "    peer_p, peer_s, peer_u = P_off[p]['vector'], P_off[s]['vector'], P_off[u]['vector']\n",
    "    chi_n = random.uniform(0.5, 1.0)\n",
    "    for d in range(D):\n",
    "        if random.random() < p_n_PL:\n",
    "            Xn[d] = peer_p[d] + chi_n * (peer_s[d] - peer_u[d])\n",
    "    Xn = apply_constraints(Xn,\n",
    "                NConv_min, NConv_max,\n",
    "                NFil_min, NFil_max,\n",
    "                SKer_min, SKer_max,\n",
    "                SPool_min, SPool_max,\n",
    "                SStr_min, SStr_max,\n",
    "                NFc_min, NFc_max,\n",
    "                NNeu_min, Nneu_max )\n",
    "    \n",
    "    fitness_adaptive_learner = evaluate_fitness(Xn, R_train, R_valid, NConv_max,S_batch = 128, ε_train = 1,\n",
    "                                    R_L = 0.001, C_num = 10,\n",
    "                                    input_shape =  (28,28,1))\n",
    "    if fitness_adaptive_learner < learner['fitness']:\n",
    "        updated_learner = {\"vector\": Xn, \"fitness\": fitness_adaptive_learner}\n",
    "        if fitness_adaptive_learner < teacher['fitness']:\n",
    "            teacher['vector'] = Xn.copy()\n",
    "            teacher['fitness'] = fitness_adaptive_learner\n",
    "            logging.info(f\"New Teacher found via Self-Learning Fitness: {fitness_adaptive_learner:.4f} ***\")\n",
    "        return updated_learner,teacher\n",
    "    else:\n",
    "        return learner, teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35483222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 18:43:44,718 - INFO - xmin and xmax initialize\n",
      "2025-08-22 18:43:44,744 - INFO - xmax [  3. 256.   9. 256.   9. 256.   9.   1.   3.   2.   1.   3.   2.   1.\n",
      "   3.   2.   2. 300. 300.]\n",
      "x min  [1. 3. 3. 3. 3. 3. 3. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "2025-08-22 18:43:44,745 - INFO - Initializing population\n",
      "2025-08-22 18:43:44,748 - INFO - Evaluating Fitness\n",
      "2025-08-22 18:43:44,751 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 18:47:16,029 - INFO - Learner 1 initialized with fitness: 0.0175\n",
      "2025-08-22 18:47:16,033 - INFO - *** New Teacher found! Fitness: 0.0175 ***\n",
      "2025-08-22 18:47:16,035 - INFO - Evaluating Fitness\n",
      "2025-08-22 18:47:16,037 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 18:48:43,785 - INFO - Learner 2 initialized with fitness: 0.0364\n",
      "2025-08-22 18:48:43,786 - INFO - Evaluating Fitness\n",
      "2025-08-22 18:48:43,789 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 18:51:42,440 - INFO - Learner 3 initialized with fitness: 0.0175\n",
      "2025-08-22 18:51:42,442 - INFO - Evaluating Fitness\n",
      "2025-08-22 18:51:42,445 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 18:55:36,153 - INFO - Learner 4 initialized with fitness: 0.1772\n",
      "2025-08-22 18:55:36,155 - INFO - Evaluating Fitness\n",
      "2025-08-22 18:55:36,156 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 19:14:58,887 - INFO - Learner 5 initialized with fitness: 0.1174\n",
      "2025-08-22 19:14:58,889 - INFO - Evaluating Fitness\n",
      "2025-08-22 19:14:58,890 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 19:23:50,413 - INFO - Learner 6 initialized with fitness: 0.0171\n",
      "2025-08-22 19:23:50,415 - INFO - *** New Teacher found! Fitness: 0.0171 ***\n",
      "2025-08-22 19:23:50,417 - INFO - Evaluating Fitness\n",
      "2025-08-22 19:23:50,418 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 19:25:26,022 - INFO - Learner 7 initialized with fitness: 0.0308\n",
      "2025-08-22 19:25:26,024 - INFO - Evaluating Fitness\n",
      "2025-08-22 19:25:26,027 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 19:30:01,036 - INFO - Learner 8 initialized with fitness: 0.0278\n",
      "2025-08-22 19:30:01,040 - INFO - Evaluating Fitness\n",
      "2025-08-22 19:30:01,042 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 19:31:13,617 - INFO - Learner 9 initialized with fitness: 0.3713\n",
      "2025-08-22 19:31:13,619 - INFO - Evaluating Fitness\n",
      "2025-08-22 19:31:13,620 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 19:31:39,655 - INFO - Learner 10 initialized with fitness: 0.0188\n",
      "2025-08-22 19:31:39,658 - INFO - Evaluating Fitness\n",
      "2025-08-22 19:31:39,658 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 19:47:39,453 - INFO - Learner 11 initialized with fitness: 0.0484\n",
      "2025-08-22 19:47:39,459 - INFO - Evaluating Fitness\n",
      "2025-08-22 19:47:39,460 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 20:01:43,633 - INFO - Learner 12 initialized with fitness: 0.0250\n",
      "2025-08-22 20:01:43,638 - INFO - Evaluating Fitness\n",
      "2025-08-22 20:01:43,639 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 20:02:06,858 - INFO - Learner 13 initialized with fitness: 0.0236\n",
      "2025-08-22 20:02:06,859 - INFO - Evaluating Fitness\n",
      "2025-08-22 20:02:06,860 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 20:04:00,655 - INFO - Learner 14 initialized with fitness: 0.0573\n",
      "2025-08-22 20:04:00,657 - INFO - Evaluating Fitness\n",
      "2025-08-22 20:04:00,657 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 20:20:27,929 - INFO - Learner 15 initialized with fitness: 0.0231\n",
      "2025-08-22 20:20:27,941 - INFO - Evaluating Fitness\n",
      "2025-08-22 20:20:27,943 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 20:22:27,273 - INFO - Learner 16 initialized with fitness: 0.0319\n",
      "2025-08-22 20:22:27,276 - INFO - Evaluating Fitness\n",
      "2025-08-22 20:22:27,276 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 20:29:28,416 - INFO - Learner 17 initialized with fitness: 0.0545\n",
      "2025-08-22 20:29:28,436 - INFO - Evaluating Fitness\n",
      "2025-08-22 20:29:28,439 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 20:29:28,652 - INFO - Error in fitness evaluation\n",
      "2025-08-22 20:29:28,655 - INFO - Learner 18 initialized with fitness: inf\n",
      "2025-08-22 20:29:28,658 - INFO - Evaluating Fitness\n",
      "2025-08-22 20:29:28,661 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 20:33:07,343 - INFO - Learner 19 initialized with fitness: 0.0159\n",
      "2025-08-22 20:33:07,354 - INFO - *** New Teacher found! Fitness: 0.0159 ***\n",
      "2025-08-22 20:33:07,355 - INFO - Evaluating Fitness\n",
      "2025-08-22 20:33:07,357 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 20:37:26,615 - INFO - Learner 20 initialized with fitness: 0.0210\n",
      "2025-08-22 20:37:26,631 - INFO - \n",
      "Starting Generation 1/10\n",
      "2025-08-22 20:37:26,635 - INFO - Starting modified teacher phase\n",
      "2025-08-22 20:37:26,675 - INFO - done making unique and social exemplar\n",
      "2025-08-22 20:37:26,679 - INFO - Processing Learner in teacher phase 1/20...\n",
      "2025-08-22 20:37:26,684 - INFO - doing boundry check  and rounding integer of new offspring generated in teacher phase\n",
      "2025-08-22 20:37:26,688 - INFO - Evaluating Fitness\n",
      "2025-08-22 20:37:26,691 - INFO - making cnn(decoding xn to cnn model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying statement\n",
      "dlc 1\n",
      "dlc 2 (hence model upper made)\n",
      "dfc 3 ffn ready hence no error\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 403\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T_max):\n\u001b[32m    402\u001b[39m     logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting Generation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mT_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     offspring_after_teacher, teacher = \u001b[43mmodified_teacher_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_population\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mS_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mε_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mNConv_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNConv_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mNFil_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNFil_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mSKer_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSKer_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mSPool_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSPool_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mSStr_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSStr_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mNFc_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNFc_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mNNeu_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNNeu_max\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m     offspring_after_learner, teacher = modified_learner_phase(\n\u001b[32m    414\u001b[39m         offspring_after_teacher,teacher,R_train, R_valid,\n\u001b[32m    415\u001b[39m         X_max, X_min,\n\u001b[32m   (...)\u001b[39m\u001b[32m    425\u001b[39m         input_shape \n\u001b[32m    426\u001b[39m     )\n\u001b[32m    427\u001b[39m     current_population = dual_criterion(N, current_population, offspring_after_learner)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 226\u001b[39m, in \u001b[36mmodified_teacher_phase\u001b[39m\u001b[34m(population, teacher, R_train, R_valid, S_batch, ε_train, R_L, C_num, NConv_max, NConv_min, NFil_min, NFil_max, SKer_min, SKer_max, SPool_min, SPool_max, SStr_min, SStr_max, NFc_min, NFc_max, NNeu_min, Nneu_max)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Applying Constraints = >\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[33;03m    core formula in the Teacher Phase:\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[33;03m    offspring_vector = (learner_vec +\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    215\u001b[39m \u001b[33;03m    The apply_constraints function is the engineer who looks at the \"3.5 doors\" calculation and says, That's not valid. I'll round that to 4 doors\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    217\u001b[39m offspring_vector = apply_constraints(offspring_vector,\n\u001b[32m    218\u001b[39m               NConv_min, NConv_max,\n\u001b[32m    219\u001b[39m               NFil_min, NFil_max,\n\u001b[32m   (...)\u001b[39m\u001b[32m    224\u001b[39m               NNeu_min, Nneu_max \n\u001b[32m    225\u001b[39m               )\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m offspring_fitness = \u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffspring_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNConv_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mε_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m offspring = {\u001b[33m\"\u001b[39m\u001b[33mvector\u001b[39m\u001b[33m\"\u001b[39m: offspring_vector, \u001b[33m\"\u001b[39m\u001b[33mfitness\u001b[39m\u001b[33m\"\u001b[39m: offspring_fitness}\n\u001b[32m    228\u001b[39m P_off.append(offspring)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mevaluate_fitness\u001b[39m\u001b[34m(Xn, R_train, R_valid, NConv_max, S_batch, ε_train, R_L, C_num, input_shape)\u001b[39m\n\u001b[32m     78\u001b[39m x_train, y_train = R_train\n\u001b[32m     79\u001b[39m x_val, y_val = R_valid\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mε_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mR_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m  \u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[32m3\u001b[39m)\n\u001b[32m     89\u001b[39m loss, accuracy = model.evaluate(x_val, y_val, verbose=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1550\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1560\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1561\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1562\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1566\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1567\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hitan\\Desktop\\coding\\MTLBORKS -CNN implimetation\\mtl\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def initialize_population(\n",
    "    N,  # population size\n",
    "    NConv_min, NConv_max,\n",
    "    NFil_min, NFil_max,\n",
    "    SKer_min, SKer_max,\n",
    "    SPool_min, SPool_max,\n",
    "    SStr_min, SStr_max,\n",
    "    NFC_min, NFC_max,\n",
    "    NNeu_min, NNeu_max,\n",
    "    R_train, R_valid, checkpoint_file\n",
    "):\n",
    "    logging.info(\"Initializing population\")\n",
    "    D = 5 * NConv_max + NFC_max + 2\n",
    "    teacher_solution = {\n",
    "        \"vector\": None,\n",
    "        \"fitness\": float('inf')\n",
    "    }\n",
    "    start_n = 0\n",
    "    population = []\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'rb') as f:\n",
    "            checkpoint = pickle.load(f)\n",
    "            start_n = checkpoint['n'] + 1\n",
    "            population = checkpoint['population']\n",
    "            teacher_solution = checkpoint['teacher']\n",
    "            logging.info(f\"--- Resuming initialization from learner {start_n + 1} ---\")\n",
    "    for n in range(start_n,N):\n",
    "        Xn = np.zeros(D)\n",
    "        NConv = random.randint(NConv_min, NConv_max) #initializing eith number of learners\n",
    "        Xn[0] = NConv\n",
    "        for l in range(1,NConv_max+1):\n",
    "            NFil = random.randint(NFil_min, NFil_max)\n",
    "            SKer = random.randint(SKer_min, SKer_max)\n",
    "            Xn[2*l - 1] = NFil\n",
    "            Xn[2*l] = SKer\n",
    "        for l in range(1,NConv_max+1):\n",
    "            PPool = random.uniform(0, 1)\n",
    "            SPool = random.randint(SPool_min, SPool_max)\n",
    "            SStr = random.randint(SStr_min, SStr_max)\n",
    "            base_idx = 2 * NConv_max\n",
    "            Xn[base_idx+3*l-2] = PPool\n",
    "            Xn[base_idx+3*l-1] = SPool\n",
    "            Xn[base_idx+3*l] = SStr\n",
    "        fc_base_idx = 5 * NConv_max + 1\n",
    "        Xn[fc_base_idx]= random.randint(NFC_min, NFC_max)\n",
    "        for q in range(1,NFC_max+1):\n",
    "            Xn[fc_base_idx + q]= random.randint(NNeu_min, NNeu_max)\n",
    "        \n",
    "        fitness = evaluate_fitness(Xn,R_train, R_valid,NConv_max)\n",
    "\n",
    "        learner_solution = {\n",
    "            \"vector\": Xn,\n",
    "            \"fitness\": fitness\n",
    "        }\n",
    "        population.append(learner_solution)\n",
    "        logging.info(f\"Learner {n+1} initialized with fitness: {fitness:.4f}\")\n",
    "        if fitness < teacher_solution[\"fitness\"]:\n",
    "            teacher_solution[\"vector\"] = Xn.copy()\n",
    "            teacher_solution[\"fitness\"] = fitness\n",
    "            logging.info(f\"*** New Teacher found! Fitness: {fitness:.4f} ***\")\n",
    "        init_checkpoint = {\n",
    "            'n': n,\n",
    "            'population': population,\n",
    "            'teacher': teacher_solution\n",
    "        }\n",
    "        with open(checkpoint_file, 'wb') as f:\n",
    "            pickle.dump(init_checkpoint, f)\n",
    "    return population, teacher_solution\n",
    "        \n",
    "        \n",
    "def evaluate_fitness(\n",
    "    Xn,R_train, R_valid,NConv_max,\n",
    "    S_batch = 128, ε_train = 1,\n",
    "    R_L = 0.001, C_num = 10,\n",
    "    input_shape =  (28,28,1)\n",
    "):\n",
    "    logging.info(\"Evaluating Fitness\")\n",
    "    try:\n",
    "        print(\"trying statement\")\n",
    "        model = decode_learner_to_cnn(\n",
    "                Xn, NConv_max,\n",
    "                input_shape,\n",
    "                C_num\n",
    "            )\n",
    "        print(1)\n",
    "        optimizer = Adam(learning_rate=R_L)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(2)\n",
    "        x_train, y_train = R_train\n",
    "        x_val, y_val = R_valid\n",
    "        model.fit(\n",
    "                x_train, y_train,\n",
    "                epochs=ε_train,\n",
    "                batch_size=S_batch,\n",
    "                validation_data=R_valid,\n",
    "                verbose=0  \n",
    "            )\n",
    "        print(3)\n",
    "        \n",
    "        loss, accuracy = model.evaluate(x_val, y_val, verbose=0)\n",
    "        # The fitness is simply the error\n",
    "        classification_error = 1.0 - accuracy\n",
    "        return classification_error\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.info(f\"Error in fitness evaluation\")\n",
    "        return float('inf')\n",
    "\n",
    "\n",
    "def decode_learner_to_cnn(Xn, NConv_max,\n",
    "                          input_shape =  (28,28,1),C_num = 10\n",
    "            ):\n",
    "    logging.info(\"making cnn(decoding xn to cnn model)\")\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=input_shape))\n",
    "    NConv = int(Xn[0])\n",
    "    NFC = int(Xn[5 * NConv_max +1])\n",
    "    print(\"dlc 1\")\n",
    "    for l in range(1,NConv+1):\n",
    "        NFil = int(Xn[2 * l-1])\n",
    "        SKer = int(Xn[2 * l])\n",
    "        model.add(Conv2D(\n",
    "                filters=NFil,\n",
    "                kernel_size=(SKer, SKer),\n",
    "                activation='relu',\n",
    "                padding='valid',\n",
    "                kernel_initializer='he_normal' \n",
    "            ))\n",
    "        model.add(BatchNormalization())\n",
    "        pooling_type_d = 2 * NConv_max + 3 * l - 2\n",
    "        kernal_size_of_pooling_layer = 2 * NConv_max + 3 * l - 1\n",
    "        stride_size_of_polling_layer = 2 * NConv_max + 3 * l \n",
    "        PPool = Xn[pooling_type_d]\n",
    "        SPool = int(Xn[kernal_size_of_pooling_layer])\n",
    "        SStr = int(Xn[stride_size_of_polling_layer])\n",
    "        if 0 <= PPool < 1/3:\n",
    "            pass  # No pooling\n",
    "        elif 1/3 <= PPool < 2/3:\n",
    "            model.add(MaxPooling2D(pool_size=(SPool, SPool), strides=(SStr, SStr)))\n",
    "        else:  # PPool ≥ 2/3\n",
    "            model.add(AveragePooling2D(pool_size=(SPool, SPool), strides=(SStr, SStr)))\n",
    "    \n",
    "    print(\"dlc 2 (hence model upper made)\")    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for q in range(1, NFC + 1):\n",
    "        dimension_of_fully_connected_layer = (5 * NConv_max + 1) + q\n",
    "        num_neurons = int(Xn[dimension_of_fully_connected_layer])\n",
    "        model.add(Dense(num_neurons, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(C_num, activation='softmax'))\n",
    "    print(\"dfc 3 ffn ready hence no error\")\n",
    "    return model\n",
    "        \n",
    "        \n",
    "def modified_teacher_phase(population, teacher, R_train, R_valid,\n",
    "                           S_batch , ε_train, R_L, C_num,\n",
    "                           NConv_max,NConv_min,\n",
    "                           NFil_min, NFil_max,\n",
    "                           SKer_min, SKer_max,\n",
    "                           SPool_min, SPool_max,\n",
    "                           SStr_min, SStr_max,\n",
    "                           NFc_min, NFc_max,\n",
    "                           NNeu_min, Nneu_max \n",
    "                           ):\n",
    "    # population => [learner_solution = {\n",
    "        #     \"vector\": Xn,\n",
    "        #     \"fitness\": fitness\n",
    "        # }]  -- at ith is knows as learner\n",
    "    # teacher_solution => teacher_solution = {\n",
    "        # \"vector\": None,             #best vector(Xn)\n",
    "    #     \"fitness\": float('inf')     # best fitness\n",
    "    # }\n",
    "    logging.info(\"Starting modified teacher phase\")\n",
    "    sorted_population = sorted(population, key=lambda x: x['fitness'], reverse=True)\n",
    "    N = len(sorted_population)\n",
    "    D = len(sorted_population[0]['vector'])\n",
    "    unique_means = []\n",
    "    for n in range(N):\n",
    "        fitter_learners = sorted_population[n:]\n",
    "        mean_vector = np.mean([learner['vector'] for learner in fitter_learners], axis=0)\n",
    "        unique_means.append(mean_vector)\n",
    "    \n",
    "    unique_social_exemplars = []\n",
    "    for n in range(N):\n",
    "        if n == N - 1:\n",
    "            unique_social_exemplars.append(None)\n",
    "            continue\n",
    "        exemplar_vector = np.zeros(D)\n",
    "        for d in range(D):\n",
    "            better_learner_idx = random.randint(n + 1, N - 1)\n",
    "            exemplar_vector[d] = sorted_population[better_learner_idx]['vector'][d]\n",
    "        unique_social_exemplars.append(exemplar_vector)\n",
    "    \n",
    "    logging.info(\"done making unique and social exemplar\")\n",
    "    \n",
    "    P_off = []\n",
    "    current_teacher = teacher.copy()\n",
    "    for n in range(N):\n",
    "        learner = sorted_population[n]\n",
    "        if n == N - 1:\n",
    "            P_off.append(learner)\n",
    "            logging.info(f\"Best learner {n+1} carried over. Fitness: {learner['fitness']:.4f}\")\n",
    "            continue\n",
    "        \n",
    "        logging.info(f\"Processing Learner in teacher phase {n+1}/{N}...\")\n",
    "        r3, r4 = random.random(), random.random()\n",
    "        F_T = random.choice([1, 2])\n",
    "        teacher_vec = current_teacher['vector']\n",
    "        learner_vec = learner['vector']\n",
    "        mean_vec = unique_means[n]\n",
    "        social_exemplar_vec = unique_social_exemplars[n]\n",
    "        # Xn_Off = learner_vec + r3*(teacher_vec - F_T * mean_vec) + r4*(social_exemplar_vec - learner_vec)\n",
    "        offspring_vector = (learner_vec + \n",
    "                            r3 * (teacher_vec - F_T * mean_vec) + \n",
    "                            r4 * (social_exemplar_vec - learner_vec))\n",
    "        \n",
    "    \n",
    "        \"\"\"Applying Constraints = >\n",
    "            core formula in the Teacher Phase:\n",
    "            offspring_vector = (learner_vec +\n",
    "                                r3 * (teacher_vec - F_T * mean_vec) +\n",
    "                                r4 * (social_exemplar_vec - learner_vec))\n",
    "            This is just vector math. The result of these additions and subtractions is guaranteed to produce numbers that are not clean\n",
    "            simple analogy: Imagine you are designing a car, and the number of doors must be an integer between 2 and 5. You have two designs, one with 2 doors and one with 5. If you average them, you get 3.5 doors. This is a mathematically correct, but you can't build a car with 3.5 doors.\n",
    "            The apply_constraints function is the engineer who looks at the \"3.5 doors\" calculation and says, That's not valid. I'll round that to 4 doors\n",
    "        \"\"\"\n",
    "        offspring_vector = apply_constraints(offspring_vector,\n",
    "                      NConv_min, NConv_max,\n",
    "                      NFil_min, NFil_max,\n",
    "                      SKer_min, SKer_max,\n",
    "                      SPool_min, SPool_max,\n",
    "                      SStr_min, SStr_max,\n",
    "                      NFc_min, NFc_max,\n",
    "                      NNeu_min, Nneu_max \n",
    "                      )\n",
    "        offspring_fitness = evaluate_fitness(offspring_vector, R_train, R_valid, NConv_max, S_batch, ε_train, R_L, C_num)\n",
    "        offspring = {\"vector\": offspring_vector, \"fitness\": offspring_fitness}\n",
    "        P_off.append(offspring)\n",
    "        logging.info(f\"\"\"\n",
    "              before implementing teacher phase learner fitness :{learner['fitness']}\n",
    "              Offspring created with fitness: {offspring_fitness:.4f}\"\"\")\n",
    "        if offspring_fitness < current_teacher['fitness']:\n",
    "            current_teacher['vector'] = offspring_vector.copy()\n",
    "            current_teacher['fitness'] = offspring_fitness\n",
    "            logging.info(f\"  -> *** New Teacher found! Fitness: {offspring_fitness:.4f} ***\")\n",
    "    \n",
    "    return P_off, current_teacher\n",
    "\n",
    "\n",
    "def modified_learner_phase(P_off,teacher,R_train, R_valid,\n",
    "                            X_max, X_min,\n",
    "                            NConv_min, NConv_max,\n",
    "                            NFil_min, NFil_max,\n",
    "                            SKer_min, SKer_max,\n",
    "                            SPool_min, SPool_max,\n",
    "                            SStr_min, SStr_max,\n",
    "                            NFc_min, NFc_max,\n",
    "                            NNeu_min, Nneu_max,\n",
    "                            S_batch = 128, ε_train = 1,\n",
    "                            R_L = 0.001, C_num = 10,\n",
    "                            input_shape =  (28,28,1)):\n",
    "    logging.info(\"Modified_learner_pahse\")\n",
    "    P_off = sorted(P_off,key = lambda x:x[\"fitness\"], reverse = True)\n",
    "    N = len(P_off)\n",
    "    D = len(P_off[0]['vector'])\n",
    "    current_teacher = teacher.copy()\n",
    "    updated_offspring_population = []\n",
    "    for n in range(N):\n",
    "        learner = P_off[n]\n",
    "        logging.info(f\"Processing Learner in learner phase {n+1}/{N}\")\n",
    "        r6 = random.random()\n",
    "        P_SL = 1/D\n",
    "        if r6<P_SL:\n",
    "            logging.info(\"Performing Self-Learning\")\n",
    "            updated_learner, current_teacher = self_learning_schema(learner,current_teacher,\n",
    "                        X_max, X_min,\n",
    "                        NConv_min, NConv_max,\n",
    "                        NFil_min, NFil_max,\n",
    "                        SKer_min, SKer_max,\n",
    "                        SPool_min, SPool_max,\n",
    "                        SStr_min, SStr_max,\n",
    "                        NFc_min, NFc_max,\n",
    "                        NNeu_min, Nneu_max,\n",
    "                        R_train, R_valid,S_batch, ε_train = 1,\n",
    "                        R_L = 0.001, C_num = 10,\n",
    "                        input_shape =  (28,28,1)\n",
    "                        )\n",
    "        else:\n",
    "            logging.info(\"Performing Adaptive lerning\")\n",
    "            updated_learner, current_teacher = adaptive_peer_learning(n, P_off, current_teacher,NFil_min, NFil_max,\n",
    "                                                    SKer_min, SKer_max,\n",
    "                                                    SPool_min, SPool_max,\n",
    "                                                    SStr_min, SStr_max,\n",
    "                                                    NFc_min, NFc_max,\n",
    "                                                    NNeu_min, Nneu_max,R_train,R_valid,S_batch = 128, ε_train = 1,\n",
    "                                                    R_L = 0.001, C_num = 10,\n",
    "                                                    input_shape =  (28,28,1))\n",
    "        updated_offspring_population.append(updated_learner)\n",
    "    return updated_offspring_population, current_teacher\n",
    "\n",
    "\n",
    "def dual_criterion(N, current_pop, offspring_pop):\n",
    "    logging.info(\"dual_criterion\")\n",
    "    merged_population = current_pop + offspring_pop\n",
    "    merged_population.sort(key=lambda x: x['fitness'])\n",
    "    \n",
    "    best_vector = merged_population[0]['vector']\n",
    "    for learner in merged_population:\n",
    "        learner['diversity'] = euclidean(learner['vector'], best_vector)\n",
    "    K = random.randint(1, N)\n",
    "    next_generation = merged_population[:K]\n",
    "    candidates = merged_population[K:]\n",
    "    if not candidates:\n",
    "        return next_generation\n",
    "    fitness_values = [c['fitness'] for c in candidates]\n",
    "    diversity_values = [c['diversity'] for c in candidates]\n",
    "    F_min, F_max = min(fitness_values), max(fitness_values)\n",
    "    Dis_min, Dis_max = min(diversity_values), max(diversity_values)\n",
    "    for _ in range(N - K):\n",
    "        tourn_a, tourn_b = random.sample(candidates, 2)\n",
    "        alpha = np.random.normal(0.9, 0.05)\n",
    "        alpha = np.clip(alpha, 0.8, 1.0)\n",
    "        f_range = F_max - F_min if F_max > F_min else 1\n",
    "        d_range = Dis_max - Dis_min if Dis_max > Dis_min else 1\n",
    "        wf_a = alpha * ((tourn_a['fitness'] - F_min) / f_range) + (1 - alpha) * ((Dis_max - tourn_a['diversity']) / d_range)\n",
    "        wf_b = alpha * ((tourn_b['fitness'] - F_min) / f_range) + (1 - alpha) * ((Dis_max - tourn_b['diversity']) / d_range)\n",
    "        winner = tourn_a if wf_a <= wf_b else tourn_b\n",
    "        next_generation.append(winner)\n",
    "        candidates.remove(winner)\n",
    "    return next_generation\n",
    "    \n",
    "\n",
    "def load_dataset(dataset_name='mnist'):\n",
    "    if dataset_name.lower() == 'mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    elif dataset_name.lower() == 'fashion_mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset '{dataset_name}' is not supported by this simple loader.\")\n",
    "\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "    \n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    num_classes = 10\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    R_train = (x_train, y_train)\n",
    "    R_valid = (x_test, y_test)\n",
    "    return R_train, R_valid, x_train.shape[1:], num_classes\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    log_dir = \"loging\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    log_file = os.path.join(log_dir, 'result.log')\n",
    "    main_checkpoint_file = os.path.join(log_dir, 'checkpoint.pkl')\n",
    "    init_checkpoint_file = os.path.join(log_dir, 'initialization_checkpoint.pkl')\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, mode='w'), \n",
    "            logging.StreamHandler() \n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    ε_train = epochs_fitness\n",
    "    R_train, R_valid, input_shape, C_num = load_dataset('mnist')\n",
    "    X_min, X_max = get_boundary_arrays(NConv_min, NConv_max,\n",
    "    NFil_min, NFil_max,\n",
    "    SKer_min, SKer_max,\n",
    "    SPool_min, SPool_max,\n",
    "    SStr_min, SStr_max,\n",
    "    NFc_min, NFc_max,\n",
    "    NNeu_min, NNeu_max)\n",
    "    # current_population, teacher = initialize_population(\n",
    "    #     N,  # population size\n",
    "    #     NConv_min, NConv_max,\n",
    "    #     NFil_min, NFil_max,\n",
    "    #     SKer_min, SKer_max,\n",
    "    #     SPool_min, SPool_max,\n",
    "    #     SStr_min, SStr_max,\n",
    "    #     NFc_min, NFc_max,\n",
    "    #     NNeu_min, NNeu_max,\n",
    "    #     R_train, R_valid\n",
    "    #     )\n",
    "    start_generation = 0\n",
    "    if os.path.exists(main_checkpoint_file):\n",
    "        with open(main_checkpoint_file, 'rb') as f:\n",
    "            checkpoint = pickle.load(f)\n",
    "            start_generation = checkpoint['generation'] + 1\n",
    "            current_population = checkpoint['population']\n",
    "            teacher = checkpoint['teacher']\n",
    "            logging.info(f\"\\n\\n--- Resuming from checkpoint at Generation {start_generation} ---\")\n",
    "    else:\n",
    "        current_population, teacher = initialize_population(\n",
    "            N,  # population size\n",
    "            NConv_min, NConv_max,\n",
    "            NFil_min, NFil_max,\n",
    "            SKer_min, SKer_max,\n",
    "            SPool_min, SPool_max,\n",
    "            SStr_min, SStr_max,\n",
    "            NFc_min, NFc_max,\n",
    "            NNeu_min, NNeu_max,\n",
    "            R_train, R_valid,\n",
    "            init_checkpoint_file\n",
    "            )\n",
    "        if os.path.exists(init_checkpoint_file):\n",
    "            os.remove(init_checkpoint_file)\n",
    "\n",
    "    for t in range(start_generation,T_max):\n",
    "        logging.info(f\"\\nStarting Generation {t+1}/{T_max}\")\n",
    "        offspring_after_teacher, teacher = modified_teacher_phase(current_population, teacher, R_train, R_valid,\n",
    "                           S_batch , ε_train, R_L, C_num,\n",
    "                           NConv_max,NConv_min,\n",
    "                           NFil_min, NFil_max,\n",
    "                           SKer_min, SKer_max,\n",
    "                           SPool_min, SPool_max,\n",
    "                           SStr_min, SStr_max,\n",
    "                           NFc_min, NFc_max,\n",
    "                           NNeu_min, NNeu_max\n",
    "        )\n",
    "        offspring_after_learner, teacher = modified_learner_phase(\n",
    "            offspring_after_teacher,teacher,R_train, R_valid,\n",
    "            X_max, X_min,\n",
    "            NConv_min, NConv_max,\n",
    "            NFil_min, NFil_max,\n",
    "            SKer_min, SKer_max,\n",
    "            SPool_min, SPool_max,\n",
    "            SStr_min, SStr_max,\n",
    "            NFc_min, NFc_max,\n",
    "            NNeu_min, NNeu_max,\n",
    "            S_batch, ε_train,\n",
    "            R_L , C_num,\n",
    "            input_shape \n",
    "        )\n",
    "        current_population = dual_criterion(N, current_population, offspring_after_learner)\n",
    "        current_population.sort(key=lambda x: x['fitness'])\n",
    "        if current_population[0]['fitness'] < teacher['fitness']:\n",
    "            teacher = current_population[0].copy()\n",
    "            logging.info(f\"Teacher updated after selection. New best fitness: {teacher['fitness']:.4f}\")\n",
    "        # --- Save Checkpoint ---\n",
    "        checkpoint = {\n",
    "            'generation': t,\n",
    "            'population': current_population,\n",
    "            'teacher': teacher\n",
    "        }\n",
    "        with open(main_checkpoint_file, 'wb') as f:\n",
    "            pickle.dump(checkpoint, f)\n",
    "        logging.info(f\"--- Checkpoint saved for Generation {t+1} ---\")\n",
    "\n",
    "    \n",
    "    logging.info(\"\\n MTLBORKS-CNN Search Complete\")\n",
    "    logging.info(f\"Final best fitness found (Teacher): {teacher['fitness']:.4f}\")\n",
    "    logging.info(\"Starting full training on the best discovered architecture\")\n",
    "    final_model = decode_learner_to_cnn(teacher['vector'], NConv_max, input_shape,C_num)\n",
    "    final_model.compile(optimizer=Adam(learning_rate=R_L), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    final_model.fit(\n",
    "        R_train[0], R_train[1],\n",
    "        batch_size=S_batch,\n",
    "        epochs=epochs_full_training,\n",
    "        validation_data=R_valid,\n",
    "        verbose=1 \n",
    "    )\n",
    "    \n",
    "    final_loss, final_accuracy = final_model.evaluate(R_valid[0], R_valid[1], verbose=0)\n",
    "    logging.info(\"\\n--- Final Model Performance ---\")\n",
    "    logging.info(f\"Final Accuracy: {final_accuracy * 100:.2f}%\")\n",
    "    logging.info(f\"Final Classification Error: {1 - final_accuracy:.4f}\")\n",
    "    final_model.summary()\n",
    "\n",
    "                \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                                                   \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c1a63",
   "metadata": {},
   "source": [
    "# Debugging \n",
    "               |\n",
    "               v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c143c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(current_population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63cf5d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vector': array([1.00000000e+00, 1.33000000e+02, 3.00000000e+00, 2.56000000e+02,\n",
       "        7.00000000e+00, 1.97000000e+02, 9.00000000e+00, 2.02249409e-02,\n",
       "        3.00000000e+00, 2.00000000e+00, 7.26936267e-01, 1.00000000e+00,\n",
       "        1.00000000e+00, 4.48897463e-01, 1.00000000e+00, 1.00000000e+00,\n",
       "        2.00000000e+00, 2.49000000e+02, 2.63000000e+02]),\n",
       " 'fitness': 0.2671999931335449}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99958989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vector': array([2.00000000e+00, 1.70000000e+02, 5.00000000e+00, 1.10000000e+01,\n",
       "        7.00000000e+00, 1.28000000e+02, 6.00000000e+00, 2.04849320e-01,\n",
       "        1.00000000e+00, 2.00000000e+00, 2.60615746e-01, 3.00000000e+00,\n",
       "        2.00000000e+00, 6.37202233e-01, 1.00000000e+00, 1.00000000e+00,\n",
       "        2.00000000e+00, 2.34000000e+02, 2.70000000e+02]),\n",
       " 'fitness': 0.14660000801086426}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_population[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8253cf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vector': array([2.00000000e+00, 1.12000000e+02, 5.00000000e+00, 5.20000000e+01,\n",
      "       5.00000000e+00, 2.23000000e+02, 5.00000000e+00, 5.50556322e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 2.07734516e-01, 2.00000000e+00,\n",
      "       1.00000000e+00, 3.33722433e-01, 3.00000000e+00, 1.00000000e+00,\n",
      "       2.00000000e+00, 2.11000000e+02, 3.90000000e+01]), 'fitness': 0.17100000381469727}\n",
      "<class 'numpy.float64'>\n",
      "\n",
      "{'vector': array([  3.        , 152.        ,   4.        ,  99.        ,\n",
      "         7.        ,   7.        ,   8.        ,   0.34051743,\n",
      "         1.        ,   2.        ,   0.65408793,   1.        ,\n",
      "         1.        ,   0.58953316,   2.        ,   2.        ,\n",
      "         2.        , 205.        , 242.        ]), 'fitness': inf}\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(current_population[15])\n",
    "print(type(current_population[15][\"vector\"][0]))\n",
    "print(\"\")\n",
    "print(current_population[18])\n",
    "print(type(current_population[18][\"vector\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43a60fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learner 1 \n",
      " Vector [1.00000000e+00 1.33000000e+02 3.00000000e+00 2.56000000e+02\n",
      " 7.00000000e+00 1.97000000e+02 9.00000000e+00 2.02249409e-02\n",
      " 3.00000000e+00 2.00000000e+00 7.26936267e-01 1.00000000e+00\n",
      " 1.00000000e+00 4.48897463e-01 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 2.49000000e+02 2.63000000e+02]\n",
      "\n",
      " Fitness 0.2671999931335449\n",
      "learner 2 \n",
      " Vector [  1.         233.           4.         134.           4.\n",
      "  98.           5.           0.85140174   1.           2.\n",
      "   0.59453527   2.           1.           0.72745643   1.\n",
      "   1.           2.          30.         121.        ]\n",
      "\n",
      " Fitness 0.5895000100135803\n",
      "learner 3 \n",
      " Vector [2.00000000e+00 1.70000000e+02 5.00000000e+00 1.10000000e+01\n",
      " 7.00000000e+00 1.28000000e+02 6.00000000e+00 2.04849320e-01\n",
      " 1.00000000e+00 2.00000000e+00 2.60615746e-01 3.00000000e+00\n",
      " 2.00000000e+00 6.37202233e-01 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 2.34000000e+02 2.70000000e+02]\n",
      "\n",
      " Fitness 0.14660000801086426\n",
      "learner 4 \n",
      " Vector [2.00000000e+00 2.48000000e+02 7.00000000e+00 1.05000000e+02\n",
      " 4.00000000e+00 2.12000000e+02 8.00000000e+00 6.95504262e-01\n",
      " 2.00000000e+00 1.00000000e+00 2.49753100e-01 3.00000000e+00\n",
      " 1.00000000e+00 1.96302480e-01 3.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 7.50000000e+01 1.58000000e+02]\n",
      "\n",
      " Fitness 0.44110000133514404\n",
      "learner 5 \n",
      " Vector [  1.          96.           7.         111.           3.\n",
      "  88.           6.           0.76839153   2.           1.\n",
      "   0.24592976   2.           2.           0.34681067   3.\n",
      "   1.           1.          95.         158.        ]\n",
      "\n",
      " Fitness 0.16109997034072876\n",
      "learner 6 \n",
      " Vector [3.00000000e+00 2.10000000e+02 9.00000000e+00 1.71000000e+02\n",
      " 4.00000000e+00 4.30000000e+01 9.00000000e+00 6.71838461e-02\n",
      " 2.00000000e+00 1.00000000e+00 3.37845648e-01 3.00000000e+00\n",
      " 1.00000000e+00 9.87455975e-01 1.00000000e+00 2.00000000e+00\n",
      " 1.00000000e+00 1.22000000e+02 1.82000000e+02]\n",
      "\n",
      " Fitness 0.13940000534057617\n",
      "learner 7 \n",
      " Vector [  1.          20.           5.         223.           7.\n",
      " 215.           4.           0.62379114   3.           1.\n",
      "   0.98288523   3.           2.           0.76120757   3.\n",
      "   1.           1.         117.         199.        ]\n",
      "\n",
      " Fitness 0.15570002794265747\n",
      "learner 8 \n",
      " Vector [  1.         212.           3.           9.           6.\n",
      " 200.           8.           0.29880478   2.           1.\n",
      "   0.48051681   3.           2.           0.60453635   2.\n",
      "   2.           1.         234.         173.        ]\n",
      "\n",
      " Fitness 0.20499998331069946\n",
      "learner 9 \n",
      " Vector [  3.          76.           5.         226.           9.\n",
      " 233.           9.           0.64141817   2.           1.\n",
      "   0.76399866   1.           1.           0.52109107   2.\n",
      "   2.           2.         242.         114.        ]\n",
      "\n",
      " Fitness 0.1629999876022339\n",
      "learner 10 \n",
      " Vector [1.00000000e+00 6.90000000e+01 5.00000000e+00 1.37000000e+02\n",
      " 7.00000000e+00 1.68000000e+02 4.00000000e+00 6.32794009e-01\n",
      " 2.00000000e+00 2.00000000e+00 3.70714830e-02 3.00000000e+00\n",
      " 2.00000000e+00 4.74096022e-02 2.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00 5.60000000e+01 2.30000000e+01]\n",
      "\n",
      " Fitness 0.17739999294281006\n",
      "learner 11 \n",
      " Vector [3.00000000e+00 1.65000000e+02 8.00000000e+00 2.39000000e+02\n",
      " 3.00000000e+00 2.27000000e+02 6.00000000e+00 6.16152534e-01\n",
      " 3.00000000e+00 2.00000000e+00 1.07246133e-02 2.00000000e+00\n",
      " 1.00000000e+00 5.37264306e-01 1.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00 4.60000000e+01 7.40000000e+01]\n",
      "\n",
      " Fitness 0.15420001745224\n",
      "learner 12 \n",
      " Vector [1.00000000e+00 7.80000000e+01 5.00000000e+00 1.86000000e+02\n",
      " 9.00000000e+00 2.16000000e+02 7.00000000e+00 2.88665326e-01\n",
      " 1.00000000e+00 2.00000000e+00 1.65678432e-01 1.00000000e+00\n",
      " 1.00000000e+00 4.15432753e-01 3.00000000e+00 2.00000000e+00\n",
      " 1.00000000e+00 5.30000000e+01 7.00000000e+01]\n",
      "\n",
      " Fitness 0.20120000839233398\n",
      "learner 13 \n",
      " Vector [1.00000000e+00 9.80000000e+01 8.00000000e+00 2.38000000e+02\n",
      " 7.00000000e+00 1.27000000e+02 9.00000000e+00 9.53980608e-01\n",
      " 1.00000000e+00 1.00000000e+00 2.37934060e-02 1.00000000e+00\n",
      " 1.00000000e+00 5.88191476e-01 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 8.80000000e+01 1.40000000e+02]\n",
      "\n",
      " Fitness 0.23830002546310425\n",
      "learner 14 \n",
      " Vector [3.00000000e+00 1.79000000e+02 5.00000000e+00 8.30000000e+01\n",
      " 7.00000000e+00 2.22000000e+02 9.00000000e+00 2.23478976e-02\n",
      " 2.00000000e+00 1.00000000e+00 9.02815850e-01 1.00000000e+00\n",
      " 2.00000000e+00 8.24490112e-01 1.00000000e+00 2.00000000e+00\n",
      " 1.00000000e+00 1.08000000e+02 2.70000000e+02]\n",
      "\n",
      " Fitness 0.12480002641677856\n",
      "learner 15 \n",
      " Vector [  3.         103.           7.         100.           6.\n",
      " 229.           9.           0.43630996   3.           1.\n",
      "   0.76786575   1.           2.           0.33294449   3.\n",
      "   1.           1.         249.         200.        ]\n",
      "\n",
      " Fitness inf\n",
      "learner 16 \n",
      " Vector [2.00000000e+00 1.12000000e+02 5.00000000e+00 5.20000000e+01\n",
      " 5.00000000e+00 2.23000000e+02 5.00000000e+00 5.50556322e-01\n",
      " 1.00000000e+00 1.00000000e+00 2.07734516e-01 2.00000000e+00\n",
      " 1.00000000e+00 3.33722433e-01 3.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 2.11000000e+02 3.90000000e+01]\n",
      "\n",
      " Fitness 0.17100000381469727\n",
      "learner 17 \n",
      " Vector [2.00000000e+00 2.01000000e+02 3.00000000e+00 1.48000000e+02\n",
      " 9.00000000e+00 1.88000000e+02 8.00000000e+00 2.86415795e-01\n",
      " 1.00000000e+00 2.00000000e+00 1.27787726e-01 2.00000000e+00\n",
      " 1.00000000e+00 5.44250892e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 2.78000000e+02 1.29000000e+02]\n",
      "\n",
      " Fitness 0.1687999963760376\n",
      "learner 18 \n",
      " Vector [  3.          52.           9.         117.           3.\n",
      "   9.           4.           0.54079775   1.           2.\n",
      "   0.5942925    1.           2.           0.96242764   3.\n",
      "   2.           1.           1.          17.        ]\n",
      "\n",
      " Fitness inf\n",
      "learner 19 \n",
      " Vector [  3.         152.           4.          99.           7.\n",
      "   7.           8.           0.34051743   1.           2.\n",
      "   0.65408793   1.           1.           0.58953316   2.\n",
      "   2.           2.         205.         242.        ]\n",
      "\n",
      " Fitness inf\n",
      "learner 20 \n",
      " Vector [  1.         151.           4.         195.           7.\n",
      "  39.           8.           0.85171212   2.           2.\n",
      "   0.24748005   1.           1.           0.84560413   1.\n",
      "   2.           2.         213.          37.        ]\n",
      "\n",
      " Fitness 0.16589999198913574\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for learner in current_population:\n",
    "    print(f\"\\nlearner {i} \\n Vector\",learner[\"vector\"])\n",
    "    print(type(learner[\"vector\"]))\n",
    "    print(\"\\n Fitness\",learner[\"fitness\"])\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "109b9f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a6214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtl (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
